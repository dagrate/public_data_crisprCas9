{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DEDjJ5cMOU7w"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ===============================================================\n",
        "# ===      NOTEBOOK TO HIGHLIGHT HOW TO USE THE ENCODED       ===\n",
        "# ===     BUNCH DATA AND TRAIN A RANDOM FOREST CLASSIFIER     ===\n",
        "# ===============================================================\n",
        "# ===============================================================\n",
        "__date__= '19-Feb-23'\n",
        "__author__='jeremy charlier'\n",
        "__revised__='19-Feb-23'\n",
        "#\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split as ttSplit\n",
        "from sklearn.metrics import (\n",
        "  classification_report, roc_auc_score,\n",
        "  confusion_matrix, f1_score,\n",
        "  roc_curve, precision_score, recall_score,\n",
        "  auc, average_precision_score, \n",
        "  precision_recall_curve, accuracy_score)\n",
        "from sklearn.ensemble import RandomForestClassifier as RF\n",
        "P = print\n",
        "#\n",
        "class ModelPipeline():\n",
        "  def __init__(self, estimator, xtrain, ytrain, xtest, ytest):\n",
        "    self.estimator=estimator\n",
        "    self.x_train=xtrain\n",
        "    self.y_train=ytrain\n",
        "    self.x_test=xtest\n",
        "    self.y_test=ytest\n",
        "    self.ypred=np.zeros((len(self.y_test)))\n",
        "    self.yscore=np.zeros((len(self.y_test),2))\n",
        "  # end of function __init__\n",
        "  #\n",
        "  def __getstate__(self):\n",
        "    return self.__dict__.copy()\n",
        "  # end of function __getstate__\n",
        "  #\n",
        "  def brierScore(y_test, yscore):\n",
        "    \"\"\"Compute the Brier score (0 = best, 1 = worst). \n",
        "    Parameters\n",
        "    ----------\n",
        "    y_test : array-like\n",
        "      true target series\n",
        "    yscore : array-like\n",
        "      predicted scores\n",
        "    Returns\n",
        "    -------\n",
        "    bscore : float \n",
        "      Brier score\n",
        "    \"\"\"\n",
        "    bscore=(1/len(y_test))\n",
        "    bscore*=np.sum(np.power(yscore[:,1]-y_test, 2))\n",
        "    return bscore\n",
        "  # end of function brierScore\n",
        "  #\n",
        "  def dispConfMatrixAsArray(y_test, ypred, disp=True):\n",
        "    \"\"\"Display and return the confusion matrix as array.\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_test : array-like\n",
        "      true target series\n",
        "    ypred : array-like\n",
        "      predicted target series\n",
        "    disp : boolean\n",
        "      diplay the confusion matrix\n",
        "    Returns\n",
        "    -------\n",
        "    confmatrix : array-like\n",
        "      pandas dataframe of the confusion matrix\n",
        "    \"\"\"\n",
        "    confmatrix=confusion_matrix(y_test,ypred)\n",
        "    tn,fp,fn,tp=confmatrix.ravel()\n",
        "    if disp==True:\n",
        "      P('\\nConfusion Matrix')\n",
        "      P(\"%-3s\" % 'TN:', \"%-5s\" % tn,\n",
        "        \"|  %-3s\" % 'FP:', \"%-5s\" % fp)\n",
        "      P(\"%-3s\" % 'FN:', \"%-5s\" % fn,\n",
        "        \"|  %-3s\" % 'TP:', \"%-5s\" % tp)\n",
        "    return confmatrix\n",
        "  # end of function dispConfMatrixAsArray\n",
        "  #\n",
        "  def getClassificationMetricsForPreds(self):\n",
        "    \"\"\"Compute metrics for classification models using the predicted class.\n",
        "    Parameters\n",
        "    ----------\n",
        "    self : class-like\n",
        "      class object\n",
        "    \"\"\"\n",
        "    posLabel = np.unique(self.y_test)\n",
        "    P(\"%-40s\" % (\"Mean Accuracy:\"),\n",
        "      \"{:.3f}\".format(self.estimator.score(self.x_test, self.y_test))\n",
        "    )\n",
        "    for n in posLabel:\n",
        "      P(\"%-40s\" % (\"F1 Score Class \" + str(n) + \" :\"), \n",
        "        \"{:.3f}\".format(\n",
        "          f1_score(self.y_test,self.ypred,pos_label=n))\n",
        "      )\n",
        "      P(\"%-40s\" % (\"Recall Score Class \"+str(n)+\" :\"), \n",
        "        \"{:.3f}\".format(\n",
        "          recall_score(self.y_test,self.ypred,pos_label=n))\n",
        "      )\n",
        "    # end for\n",
        "  # end of function getClassificationMetricsForPreds\n",
        "  #\n",
        "  def getClassificationMetricsForScores(self):\n",
        "    \"\"\"Compute metrics for classification models using the scores.\n",
        "    Parameters\n",
        "    ----------\n",
        "    self : class-like\n",
        "      class object\n",
        "    \"\"\"\n",
        "    posLabel = np.unique(self.y_test)\n",
        "    P(\"%-40s\" % (\"ROC AUC Score:\"),\n",
        "      \"{:.3f}\".format(roc_auc_score(self.y_test, self.yscore[:,1]))\n",
        "    )\n",
        "    P(\"%-40s\" % (\"Brier Score:\"), \"{:.3f}\".format(\n",
        "      ModelPipeline.brierScore(self.y_test, self.yscore))\n",
        "    )\n",
        "    for n in posLabel:\n",
        "      P(\"%-40s\" % (\"Avrg Precision Score Class \"+str(n)+\" :\"), \n",
        "        \"{:.3f}\".format(\n",
        "          average_precision_score(self.y_test,self.yscore[:,1],pos_label=n))\n",
        "      )\n",
        "    # end for\n",
        "  # end of function getClassificationMetricsForScores\n",
        "  #\n",
        "  def getClassificationMetrics(self):\n",
        "    \"\"\"Compute metrics for classification models.\n",
        "    Parameters\n",
        "    ----------\n",
        "    self : class-like\n",
        "      class object\n",
        "    \"\"\"\n",
        "    P(\"\\nModel Metrics:\")\n",
        "    ModelPipeline.getClassificationMetricsForPreds(self)\n",
        "    if not \"RidgeClassifier\" in str(self.estimator):\n",
        "      ModelPipeline.getClassificationMetricsForScores(self)\n",
        "    # end if\n",
        "    _ = ModelPipeline.dispConfMatrixAsArray(self.y_test,self.ypred,disp=True)\n",
        "  # end of function getClassificationMetrics\n",
        "  #\n",
        "  def modelTrain(self):\n",
        "    \"\"\"Training pipeline.\n",
        "    \"\"\"\n",
        "    self.estimator=self.estimator.fit(self.x_train,self.y_train)\n",
        "    return self\n",
        "  # end of function modelTrain\n",
        "  #\n",
        "  def modelPredict(self):\n",
        "    \"\"\"Predict pipeline.\n",
        "    \"\"\"\n",
        "    self.ypred=self.estimator.predict(self.x_test)\n",
        "    if not \"RidgeClassifier\" in str(self.estimator):\n",
        "      self.yscore=self.estimator.predict_proba(self.x_test)\n",
        "    # end if\n",
        "    ModelPipeline.getClassificationMetrics(self)\n",
        "    return self\n",
        "  # end of function modeltrain\n",
        "# end of class ModelPipeline\n",
        "#\n",
        "#\n",
        "def reshapeArr(arr, est='rf'):\n",
        "  shp = np.prod(arr.shape[1:])\n",
        "  if est == 'rf':\n",
        "    arr = arr.astype('float32')\n",
        "    arr = arr.reshape(-1,shp)\n",
        "  return arr\n",
        "#\n",
        "#\n",
        "def printClassImbalance(y):\n",
        "  nmin = min((y==1).sum(), (y==0).sum())\n",
        "  nmaj = max((y==1).sum(), (y==0).sum())\n",
        "  P(\">> Nbr of samples in minority class: %s\" % nmin)\n",
        "  P(\">> Nbr of samples in majority class: %s\" % nmaj)\n",
        "  P(\">> Class imbalance: %s \" % np.round(nmin/len(y), 3))\n",
        "#\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === READ ENCODED DATA ===\n",
        "# change path_to_module by the folder path\n",
        "# update encoded_data_for_experiments.pkl by the name of your data file\n",
        "with open(path_to_module+'encoded_data_for_experiments.pkl', 'rb') as f: \n",
        "  data = pkl.load(f)\n",
        "P('Available encoded data sets for experiments:')\n",
        "P(*list(data.keys()), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duJ-ubcGPRfh",
        "outputId": "36b281ba-9a0f-41b2-d9cc-f89549e11e3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available encoded data sets for experiments:\n",
            "listgarten_elevation_cd33\n",
            "CIRCLE_seq_10gRNA\n",
            "SITE_seq_offtarget\n",
            "elevation_guideseq\n",
            "Listgarten_22gRNA\n",
            "Kleinstiver_5gRNA\n",
            "listgarten_elevation_hmg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === DATA SPLIT ===\n",
        "# select listgarten_elevation_cd33 for binary classification\n",
        "dataset = 'listgarten_elevation_cd33'\n",
        "X = data[dataset].data\n",
        "y = data[dataset].target\n",
        "#\n",
        "# print class imbalance\n",
        "P('Class Imbalance Statistics:')\n",
        "printClassImbalance(y)\n",
        "#\n",
        "# train-test split with stratification\n",
        "xtrain, xtest, ytrain, ytest = ttSplit(\n",
        "  X, y, test_size = .3, random_state = 42, stratify = y)\n",
        "#\n",
        "# 3 dimensionals are converted to 2d for classifier\n",
        "xtrain = reshapeArr(xtrain)\n",
        "xtest = reshapeArr(xtest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vnpewK_RLMm",
        "outputId": "87a88972-893f-424b-9499-f64b4df406ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Imbalance Statistics:\n",
            ">> Nbr of samples in minority class: 2273\n",
            ">> Nbr of samples in majority class: 2580\n",
            ">> Class imbalance: 0.468 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === MODEL FIT AND PREDICT ===\n",
        "clf = RF(n_estimators = 100, random_state = 42)\n",
        "mdl = ModelPipeline(\n",
        "  clf, xtrain, ytrain, xtest, ytest).modelTrain()\n",
        "mdl = mdl.modelPredict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIt19C85gClB",
        "outputId": "867acc34-7ca2-436d-db8b-309ee8976810"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Metrics:\n",
            "Mean Accuracy:                           0.740\n",
            "F1 Score Class 0.0 :                     0.716\n",
            "Recall Score Class 0.0 :                 0.615\n",
            "F1 Score Class 1.0 :                     0.761\n",
            "Recall Score Class 1.0 :                 0.883\n",
            "ROC AUC Score:                           0.885\n",
            "Brier Score:                             0.157\n",
            "Avrg Precision Score Class 0.0 :         0.352\n",
            "Avrg Precision Score Class 1.0 :         0.882\n",
            "\n",
            "Confusion Matrix\n",
            "TN: 476   |  FP: 298  \n",
            "FN: 80    |  TP: 602  \n"
          ]
        }
      ]
    }
  ]
}
